<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Proposal for an Exchange Format to support Audio Description</title>
    <script src="https://www.w3.org/Tools/respec/respec-w3c" class="remove"></script>
    <script class='remove'>
      // See https://github.com/w3c/respec/wiki/ for how to configure ReSpec
      var respecConfig = {
        specStatus: "CG-DRAFT",
        group: "cg/audio-description",
        wgPublicList: "public-audio-description",
        shortName: "adpt",
        github: "w3c/adpt",
        tocIntroductory: true,
        localBiblio: {
          "WHP051": {
            title: "BBC R&D White Paper WHP 051. Audio Description: what it is and how it works",
            publisher: " N.E. Tanton, T. Ware and M. Armstrong",
            status: "October 2002 (revised July 2004)",
            href: "http://www.bbc.co.uk/rd/publications/whitepaper051",
          },
          "MAUR": {
            title: "Media Accessibility User Requirements",
            href: "https://www.w3.org/TR/media-accessibility-reqs/",
          },
          "ADPTREQS": {
            title: "Requirements for Audio (Video) Description – DRAFT FOR REVIEW",
            publisher: "W3C TTWG",
            status: "Draft",
            href: "https://github.com/w3c/ttml2/wiki/Audio-Description-Requirements",
          },
          "ttml2": {
            "authors":["Glenn Adams","Cyril Concolato"],
            "href":"https://www.w3.org/TR/2018/REC-ttml2-20181108/",
            "title":"Timed Text Markup Language 2 (TTML2)",
            "status":"REC",
            "publisher":"W3C",
            "id":"ttml2-20181108",
            "date":"8 November 2018"
          },        },
        editors: [ 
          {
            name: "John Birch",
            company: "Screen Subtitling Systems Ltd.",
            companyURL: "http://www.subtitling.com",
          },
          {
            name: "Nigel Megitt",
            company: "British Broadcasting Corporation",
            companyURL: "https://www.bbc.co.uk/",
          }],
          authors: [ {
            name: "Peter Spoor",
            company: "The Service Station",
          },
          {
            name: "Marisa DeMeglio",
            company: "DAISY consortium",
          },
          {
            name: "Chris O’Brien",
            company: "Accessible Media INC",
          },
          {
            name: "Hewson Maxwell",
            company: "Red Bee Media",
          },
          {
            name: "Jonathan Penny",
            company: "ITV",
          },
          {
            name: "Matt Simpson",
            company: "Cut and Paste Consulting",
          },
          {
            company: "YellaUmbrella",
            name: "Simon Hailes, Matt Deakin",
          },
          {
            company: "Prime Focus",
            name: "Radhika Chinai, Gandharv Bhagat, Bipin Doshi",
          },
          {
            company: "Deluxe",
            name: "Margaret Lazenby, Ian Beushaw, Paul Gray",
          },
          {
            company: "British Broadcasting Corporation",
            name: "Nigel Megitt, Eyal Lavi",
          },
          {
            company: "RNIB",
            name: "Sonali Rai, John Paton",
          },
          {
            company: "Screen Subtitling Systems Ltd.",
            name: "John Birch",
          },
          {
            company: "Starfish",
            name: "Graham Neden-Watts",
          },
          {
            company: "SWR",
            name: "Philip Klenk"
          },
        ]
      };
    </script>
  </head>
  <body>
    <section id="abstract" class=informative>
      <p>
        <a>Audio Description</a>, also known as Video Description, is an audio service to assist viewers who can not fully see a visual presentation
        to understand the content, usually achieved by mixing a ‘<a>description</a>’ audio track
        with the <a>main programme audio</a>, at moments when this does not clash with dialogue, to deliver an <a>audio description mixed audio track</a>.
        More information about what <a>Audio Description</a> is and how it works can be found at [[WHP051]].
        </p>
      <p>
        Audio Description is usually delivered as audio, either pre-recorded or synthesised, but (until now) has not been deliverable as accessible text using an open standard.
        This report describes the requirements for text documents that can support audio description script exchange throughout the workflow from production (scripting) through to distribution (mixing either at the broadcaster or at the viewers device).
      </p>
      <p>
        This document is a Community Group Report, including 
        <a href="#requirements">requirements</a> and a proposed specification that meets the requirements.
        The proposed specification is a <a>profile</a> of the Timed Text Markup Language version 2.0 [[TTML2]].
      </p>
    </section>
    <section id="sotd">
      <p>
      </p>
    </section>
    <section id="scope">
      <h2>Scope</h2>
      <p>
        This specification defines a single text-based profile of the Timed Text Markup Language version 2.0 [[TTML2]]. This profile is intended to support audio description workflows worldwide, including description creation, script delivery and exchange and generated audio description distribution.
        The proposed profile is a syntactic subset of the Timed Text Markup Language version 2.0 [[TTML2]], and a document can simultaneously conform to both the base standard and the proposed profile.
      </p>
      <p>
        This document defines NO extensions to [[TTML2]].
      </p>
      <p>
        This document is the first version of this proposal.
      </p>
    </section>
    <section id="introduction" class="informative">
      <h2>Introduction</h2>
      <p>
        This report specifies a <a>profile</a> of [[TTML2]] that meets the <a href="#requirements">requirements</a> for documents needed to support audio description script exchange throughout the
        <a href="#workflow">workflow</a> from production (scripting) to distribution (mixing). This report also includes a proposed specification that meets those requirements,
        and serves as a basis for verifying that the proposed specification intended to support that process is suitable. It is anticipated that recent additions to Timed Text Markup Language version 2.0 [[TTML2]] are sufficient to meet all of the requirements.
        Furthermore, the requirements do not assume or require that a single document format or instance be used for every step of an Audio Description workflow, however that would appear to be desirable since it would reduce conversion step requirements.
      </p>
      <p>
        The Timed Text Markup Language version 2.0 [[TTML2]] format is an xml based [[XML]] <a>markup language</a> that specifies <a>timed text</a>, so can be used for storing the <a>audio description</a> scripts.
        This recent version of the <a>TTML</a> standard introduces audio mixing and text to speech semantics into the previous versions of the <a>TTML</a> specification.
        These new semantics support the main requirements for audio descrition, synchronised audio playback, continuous animation, control of pan / gain for audio mixing and speech rate and pitch attributes for controlling text to speech.
        There is support for these new TTML features in browsers using [[WEBAUDIO]] and WebSpeech respectively.
      </p>
      <p>
        A requirements document has been available, published and updated on github for a period of time (approximately 2 years) [[ADPTREQS]].
        It is considered that the captured requirements are valid at this point. Those requirements are included in this document as a rationale to support the proposed profile.
      </p>
      <p>
        This document proposes an Audio Description profile of TTML that will allow the delivery of an audio description script, pre-recorded audio and mixing data in a single file using an open standard format.
        The proposed profile should allow client implementations to provide real time mixing of the Audio Description, perhaps with some user customisation (like changing the relative volumes of the main programme audio and the AD audio).
        Additionally, the presentation of the Audio Desciption script text on a completely different device, like a braille display may be possible.
        A client that is hosted 'server side' would be able to create a “broadcaster mix”, whereas a “receiver mix” could be implemented by hosting the client at the viewers device.
      </p>
      <section id="intro-example">
        <h3>Example documents</h3>
        <p>The following example shows an audio description script, with times
        and text, before any audio has been added.</p>
        <pre class="example"
          data-include="examples/intro-script.xml"
          data-include-format="text">
        </pre>
        <p>References to audio recordings of the voiced words can be added:</p>
        <pre class="example"
          data-include="examples/intro-script-with-audio.xml"
          data-include-format="text">
        </pre>
        <p>If the audio recording is long and just a snippet needs to be played,
        that can be done using <code>clipBegin</code> and <code>clipEnd</code>.
        If we just want to play the part of the audio from file from 5s to
        8s it would look like:</p>
        <pre class="example"
          data-include="examples/intro-script-with-audio-clipped.xml"
          data-include-format="text">
        </pre>
        <p>Or audio attributes can be added to trigger the text to be spoken:
        </p>
        <pre class="example"
          data-include="examples/intro-script-with-speak.xml"
          data-include-format="text">
        </pre>
        <p>The gain of "received" audio can be changed before mixing in
        the audio played from inside the <code>span</code>, smoothly
        animating the value on the way in and returning it on the way out:</p>
        <pre class="example"
          data-include="examples/intro-script-with-gain.xml"
          data-include-format="text">
        </pre>
        <p>In the above example, the <code>div</code> element's
          <code>begin</code> time becomes the "syncbase" for its child, 
          so the times on the <code>animate</code> and <code>span</code> 
          elements are relative to 25s here.
          The first <code>animate</code> element drops the gain from 1
          to 0.39 over 0.3s, and the second one raises it back in the
          final 0.3s of this description. Then the <code>span</code> is
          timed to begin only after the first audio dip has finished.</p>
      </section>
    </section>
    <section id="conventions">
      <h2>Documentation Conventions</h2>
      <p>
        This document uses the same conventions as [[TTML2]] for the specification of parameter attributes, styling attributes and metadata elements. In particular:
      </p>
      <p>
        Section 2.3 of [[TTML2]] specifies conventions used in the [[XML]] representation of elements; and
        Sections 6.2 and 8.2 of [[TTML2]] specify conventions used when specifying the syntax of attribute values.
      </p>
      <p>
        All content of this specification that is not explicitly marked as non-normative is considered to be normative.
        If a section or appendix header contains the expression "non-normative", then the entirety of the section or appendix is considered non-normative.
      </p>
      <p>
        This specification uses Feature designations as defined in Appendices E at [[TTML2]]:
        when making reference to content conformance, these designations refer to the syntactic expression or the semantic capability associated with each designated Feature; and
        when making reference to processor conformance, these designations refer to processing requirements associated with each designated Feature.
        If the name of an element referenced in this specification is not namespace qualified, then the TT namespace applies (see <a href="#namespaces">9.3 Namespaces</a>.)
      </p>
    </section>
    <section id="definitions">
      <h2>Definitions</h2>
      <p>
        The following terms are used in this proposal:
      </p>
      <p>
        <dfn>Audio description</dfn>	An audio rendition of a Description or a set of Descriptions.
      </p>
      <p>
        <dfn>Audio description mixed audio track</dfn>  The output of an audio mixer incorporating the main programme audio and the audio description.
      </p>
      <p>
        <dfn>Description</dfn>  A set of words that describe an aspect of the programme presentation, suitable for rendering into audio by means of vocalisation and recording or used as a <a>Text Alternative</a> source for speech to text translation.
      </p>
      <p>
        <dfn data-cite="ttml2#terms-default-region">Default Region</dfn> See Section 11.3.1.1 at [][TTML2]].
      </p>
      <p>
        <dfn data-lt="Document Instance|Document Instances" data-cite="ttml2#terms-document-instance">Document Instance</dfn> As defined by [[TTML2]].
      </p>
      <p>
        <dfn data-cite="ttml2#terms-document-interchange-context">Document Interchange Context</dfn> As defined by [[TTML2]].
      </p>
      <p>
        <dfn data-cite="ttml2#terms-document-processing-context">Document Processing Context</dfn>  See Section 2.2 at [[TTML2]].
      </p>
      <p>
        <dfn data-cite="ttml2#terms-feature">Feature</dfn>  See Section 2.2 at [[TTML2]].
      </p>
      <p>
        <dfn data-cite="ttml2#terms-intermediate-synchronic-document">Intermediate Synchronic Document</dfn> See Section 11.3.1.3 at [[TTML2]].
      </p>
      <p>
        <dfn data-cite="ttml2#style-value-lwsp">Linear White-Space</dfn> See Section 2.3 at [[TTML2]].
      </p>
      <p>
        <dfn>Main programme audio</dfn> The audio associated with the programme prior to any mixing with audio description.
      </p>
      <p>
        <dfn>Markup Language</dfn> A human-readable computer language that uses tags to define elements within a document.
        Markup files contain standard words, rather than typical programming syntax.
      </p>
      <p>
        <dfn data-cite="ttml2#terms-presentation-processor">Presentation processor</dfn> See Section 2.2 at [[TTML2]].
      </p>
      <p>
        <dfn data-cite="ttml2#terms-processor">Processor</dfn>  Either a Presentation processor or a Transformation processor.
      </p>
      <p>
        <dfn data-cite="ttml2#terms-profile">Profile</dfn>  A TTML profile specification is a document that lists all the features of TTML that are required / optional / prohibited within “document instances” (files) and “processors” (things that process the files), and any extensions or constraints.
      </p>
      <p>
        <dfn data-cite="ttml2#terms-related-media-object">Related Media Object</dfn> See Section 2.2 at [[TTML2]].
      </p>
      <p>
        <dfn>Related Video Object</dfn> A <a>Related Media Object</a> that consists of a sequence of image frames, each a rectangular array of pixels.
      </p>
      <p>
        <dfn data-cite="ttml2#terms-root-container-region">Root Container Region</dfn>  See Section 2.2 at [[TTML2]].
      </p>
      <p>
        <dfn>Text Alternative</dfn> As defined in [[WCAG20]].
      </p>
      <p>
        <dfn>Timed Text</dfn> Text media that is presented in synchrony with other media, such as audio and video with (optional) specified text presentation styling information such as font, colour and position.
      </p>
      <p>
        <dfn data-cite="ttml2#terms-transformation-processor">Transformation processor</dfn> See Section 2.2 at [[TTML2]].
      </p>
      <p>
        <dfn>TTML</dfn> A Markup Language designed for the storage and delivery of Timed Text, as defined in [[TTML2]] primarily used in the television industry.
        TTML is used for authoring, transcoding and exchanging timed text information and for delivering captions, subtitles, and other metadata for television material repurposed for the Web or, more generally, the Internet.
      </p>
    </section>
    <section id="conformance">
      <p>
        A <a>Document Instance</a> that conforms to the profile defined herein:
      </p>
      <ul style="list-style-type:disc">
        <li>SHALL satisfy all normative provisions specified by the profile;</li>
        <li>MAY include any vocabulary, syntax or attribute value associated with a Feature whose disposition is permitted or optional in the profile;</li>
        <li>SHALL NOT include any vocabulary, syntax or attribute value associated with a Feature whose disposition is prohibited in the profile.</li>
      </ul>
      <p class="note">
        A <a>Document Instance</a>, by definition, satisfies the requirements of Section 3.1 at [[TTML2]], and hence a Document Instance that conforms to a profile defined herein is also a conforming TTML2 Document Instance.
      </p>
      <p>
        A <a>presentation processor</a> that conforms to the profile defined in this specification:
      </p>
      <ul style="list-style-type:disc">
        <li>SHALL satisfy the Generic Processor Conformance requirements at Section 3.2.1 of [[TTML2]]</li>
        <li>SHALL satisfy all normative provisions specified by the profile; and</li>
        <li>SHALL implement presentation semantic support for every Feature designated as permitted by the profile, subject to any additional constraints on each Feature as specified by the profile.</li>
        <li>MAY implement presentation semantic support for every Feature designated as optional by the profile, subject to any additional constraints on each Feature as specified by the profile.</li>
      </ul>
      <p>
        A <a>transformation processor</a> that conforms to the profile defined in this specification:
      </p>
      <ul style="list-style-type:disc">
        <li>SHALL satisfy the Generic Processor Conformance requirements at Section 3.2.1 of [[TTML2]];</li>
        <li>SHALL satisfy all normative provisions specified by the profile; and</li>
        <li>SHALL implement transformation semantic support for every Feature designated as permitted by the profile, subject to any additional constraints on each Feature as specified by the profile.</li>
        <li>MAY implement transformation semantic support for every Feature designated as optional by the profile, subject to any additional constraints on each Feature as specified by the profile.</li>
      </ul>
      <p class="ednote">
        Change DFXP to something more appropriate in the following note, or remove it altogether.
      </p>
      <p class="note">
        The use of the terms <a>presentation processor</a> 
        and <a>transformation processor</a> within this document does not imply conformance <i>per se</i> to any of the Standard Profiles defined in [[TTML2]].
        In other words, it is not considered an error for a <a>presentation processor</a> or <a>transformation processor</a> to conform to the profile defined in this document without also conforming to the TTML2  Presentation Profile or the TTML2 Transformation Profile.
      </p>
      <p class="note">
        This document does not specify presentation processor or transformation processor behavior when processing or transforming a non-conformant Document Instance.
      </p>
      <p class="note">
        The permitted and prohibited dispositions do not refer to the specification of a ttp:feature or ttp:extension element as being permitted or prohibited within a ttp:profile element.
      </p>
    </section>
    <section id="profile">
      <h2>Profile</h2>
      <section id="profile-general">
        <h3>General</h3>
        <p>
          The Profile consists of <a href="#profile-constraints" class="sec-ref">Constraints</a>.
        </p>
      </section>
      <section id="profile-resolution-semantics">
        <h3>Profile Resolution Semantics</h3>
        <p>
          For the purpose of content processing, the determination of the resolved profile SHOULD take into account both the signaled profile, as defined in <a href="#profile-signaling-section"></a>, and profile metadata, as designated by either (or both) the Document Interchange Context or (and) the Document Processing Context, which MAY entail inspecting document content.
        </p>
        <p>
          If the resolved profile is not the Profile supported by the Processor but is feasibly interoperable with the Profile, then the resolved profile is the Profile.
          If the resolved profile is undetermined or not supported by the Processor, then the Processor SHOULD nevertheless process the Document Instance using the Profile; otherwise, processing MAY be aborted.
          If the resolved profile is not the proposed Profile, processing is outside the scope of this specification.
        </p>
        <p>
          If the resolved profile is the profile supported by the Processor, then the Processor SHOULD process the Document Instance according to the Profile.
        </p>
      </section>
    </section>
    <section id="profile-constraints">
      <h2>Constraints</h2>
      <section id="Document Encoding">
        <h3>Document Encoding</h3>
        <p>
          A Document Instance SHALL use UTF-8 character encoding as specified in [[UNICODE]].
        </p>
      </section>
      <section id="foreign-elements-and-attributes">
        <h3>Foreign Element and Attributes</h3>
        <p>
          A Document Instance MAY contain elements and attributes that are neither specifically permitted nor forbidden by a profile.
        </p>
        <p>
          A transformation processor SHOULD preserve such elements or attributes whenever possible.
        </p>
        <p class ="note">
          Document Instances remain subject to the content conformance requirements specified at Section 3.1 of [[TTML2]].
          In particular, a Document Instance can contain elements and attributes not in any TT namespace, i.e. in foreign namespaces, since such elements and attributes are pruned by the algorithm at Section 4 of [[TTML2]] prior to evaluating content conformance.
        </p>
        <p class ="note">
          For validation purposes it is good practice to define and use a content specification for all foreign namespace elements and attributes used within a Document Instance.
        </p>
      </section>
      <section id="namespaces">
        <h3>Namespaces</h3>
        <p>
          The following namespaces (see [[xml-names]]) are used in this specification:
        </p>
        <table class="simple">
          <thead>
            <tr>
              <th>Name</th>
              <th>Prefix</th>
              <th>Value</th>
              <th>Defining Specification</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>XML</td>
              <td><code>xml</code></td>
              <td><code>http://www.w3.org/XML/1998/namespace</code></td>
              <td>[[xml-names]]</td>
            </tr>
            <tr>
              <td>TT</td>
              <td><code>tt</code></td>
              <td><code>http://www.w3.org/ns/ttml</code></td>
              <td>[[TTML2]]</td>
            </tr>
            <tr>
              <td>TT Parameter</td>
              <td><code>ttp</code></td>
              <td><code>http://www.w3.org/ns/ttml#parameter</code></td>
              <td>[[TTML2]]</td>
            </tr>
            <tr>
              <td>TT Feature</td>
              <td><em>none</em></td>
              <td><code>http://www.w3.org/ns/ttml/feature/</code></td>
              <td>[[TTML2]]</td>
            </tr>
            <tr>
              <td>TT Audio Style</td>
              <td><em>tta:</em></td>
              <td><code>http://www.w3.org/ns/ttml#audio</code></td>
              <td>[[TTML2]]</td>
            </tr>
            <tr>
              <td>ADPT 1.0 Profile Designator</td>
              <td><em>none</em></td>
              <td><code></code></td>
              <td><em>This specification</em></td>
            </tr>
          </tbody>
        </table>
        <p>
          The namespace prefix values defined above are for convenience and Document Instances MAY use any prefix value that conforms to [[xml-names]].
        </p>
        <p>
          The namespaces defined by this proposal document are mutable [[namespaceState]]; all undefined names in these namespaces are reserved for future standardization by the W3C.
        </p>
      </section>
      <section id="related-video-object-section">
        <h3>Related Video Object</h3>
        <p>
          A Document Instance MAY be associated with a <a>Related Video Object</a>.
        </p>
        <p class="note">
          While this specification contains specific provisions when a Document Instance is associated with a <a>Related Video Object</a>, it does not prevent the use of a Document Instance with other kinds of Related Media Object, e.g. an audio only object.
        </p>
      </section>
      <section id="synchronization-section">
        <h3>Synchronization</h3>
        <p>
          Each intermediate synchronic document of the Document Instance is intended to be presented (audible) starting on a specific frame and removed (inaudible) by a specific frame of the Related Video Object.
        </p>
        <p>
          When mapping a media time expression M to a frame F of a Related Video Object (or Related Media Object), e.g. for the purpose of mixing audio sources signalled by a Document Instance into the main program audio of the <a>Related Video Object</a>, the presentation processor SHALL map M to the frame F with the presentation time that is the closest to, but not less, than M.
        </p>
        <p>
          EXAMPLE 1
          A media time expression of 00:00:05.1 corresponds to frame ceiling( 5.1 × ( 1000 / 1001 × 30) ) = 153 of a <a>Related Video Object</a> with a frame rate of 1000 / 1001 × 30 ≈ 29.97.
        </p>
        <p class="note">
          In typical scenario, the same video program (the <a>Related Video Object</a>) will be used for Document Instance authoring, delivery and user playback.
          The mapping from media time expression to <a>Related Video Object</a> above allows the author to precisely associate audio description content with video frames, e.g. around existing audio dialogue and sound effects.
          In circumstances where the video program is downsampled during delivery, the application can specify that, at playback, the relative video object be considered the delivered video program upsampled to is original rate, thereby allowing audio content to be presented at the same temporal locations it was authored.
        </p>
      </section>
      <section id="profile-signaling-section">
        <h3>Profile Signaling</h3>
        <p>
          The ttp:profile attribute SHOULD be present on the tt element and equal to the designator of the ADPT 1.0 profile to which the Document Instance conforms.
        </p>
      </section>
      <section id="features-section">
        <h3>Features</h3>
        <p>
          See <a href="#conformance" class="sec-ref">Conformance</a> for a definition of <em>permitted</em>, <em>prohibited</em> and <em>optional</em>.
        </p>
        <table class="simple">
          <tbody>
            <tr>
              <th style="width:20%" style="text-align:center">Feature</th>
              <th style="width:10%" style="text-align:center">Disposition</th>
              <th style="text-align:center">Additional provision</th>
            </tr>
            <tr>
              <td colspan="3" style="text-align:center"><em>Relative to the TT Feature namespace</em></td>
            </tr>
            <tr>
              <td><code>#animation-version-2</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#audio</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#audio-description</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#audio-speech</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#backgroundColor-block</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#backgroundColor-region</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#cellResolution</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#chunk</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#clockMode</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#clockMode-gps</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#clockMode-local</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#clockMode-utc</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#content</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#contentProfiles</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#core</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#data</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#display-block</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#display-inline</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#display-region</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#display</code></td>
              <td>prohibited<p class="ednote">Consider display="none" in relation to AD content</p></td>
              <td></td>
            </tr>
            <tr>
              <td><code>#dropMode</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#dropMode-dropNTSC</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#dropMode-dropPAL</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#dropMode-nonDrop</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#embedded-audio</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#embedded-data</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#extent-root</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#extent</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#frameRate</code></td>
              <td>permitted</td>
              <td>
                If the <a href="#dfn-document-instance" class="internalDFN" data-link-type="dfn">Document Instance</a> includes any time expression that uses the <code>frames</code> term or any
                offset time expression that uses the <code>f</code> metric, the <code>ttp:frameRate</code> attribute <em class="rfc2119" title="SHALL">SHALL</em> be present
                on the <code>tt</code> element.
              </td>
            </tr>
            <tr>
              <td><code>#frameRateMultiplier</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#gain</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#layout</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#length-cell</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#length-integer</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#length-negative</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#length-percentage</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#length-pixel</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#length-positive</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#length-real</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#length</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#markerMode</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#markerMode-continuous</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#markerMode-discontinuous</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#metadata</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#opacity</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#origin</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#overflow</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#overflow-visible</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#pan</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#pitch</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#pixelAspectRatio</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#presentation</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#processorProfiles</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td id="profile-constraints"><code>#profile</code></td>
              <td>permitted</td>
              <td>
                See <a href="#profile-signaling-section" class="sec-ref"></a>.
              </td>
            </tr>
            <tr>
              <td><code>#region-timing</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#resources</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#showBackground</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#source</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#speak</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#speech</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#structure</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#styling</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#styling-chained</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#styling-inheritance-content</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#styling-inheritance-region</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#styling-inline</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#styling-nested</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#styling-referential</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#subFrameRate</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#tickRate</code></td>
              <td>permitted</td>
              <td><code>ttp:tickRate</code> <em class="rfc2119" title="SHALL">SHALL</em> be present on the <code>tt</code> element if the document contains any time
              expression that uses the <code>t</code> metric.</td>
            </tr>
            <tr>
              <td><code>#timeBase-clock</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#timeBase-media</code></td>
              <td>permitted</td>
              <td>
                <p class="inline-note">NOTE: [[TTML1]] specifies that the default timebase is <code>"media"</code> if
                <code>ttp:timeBase</code> is not specified on <code>tt</code>.</p>
              </td>
            </tr>
            <tr>
              <td><code>#timeBase-smpte</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#time-clock-with-frames</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#time-clock</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#time-offset-with-frames</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#time-offset-with-ticks</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#time-offset</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#timeContainer</code></td>
              <td>permitted</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#timing</code></td>
              <td>permitted</td>
              <td>
                <ul class="short-list">
                  <li>All time expressions within a <a href="#dfn-document-instance" class="internalDFN" data-link-type="dfn">Document Instance</a> <em class="rfc2119" title="SHOULD">SHOULD</em> use the same syntax, either
                  <code>clock-time</code> or <code>offset-time</code>.
                  </li>
                  <li>For any content element that contains <code>br</code> elements or text nodes or a
                  <code>smpte:backgroundImage</code> attribute, both the <code>begin</code> attribute and one of either the
                  <code>end</code> or <code>dur</code> attributes <em class="rfc2119" title="SHOULD">SHOULD</em> be specified on the content element or at least one of its
                  ancestors.</li>
                </ul>
              </td>
            </tr>
            <tr>
              <td><code>#transformation</code></td>
              <td>permitted</td>
              <td>
                See constraints at <a href="#profile-constraints">#profile</a>.
              </td>
            </tr>
            <tr>
              <td><code>#visibility-block</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#visibility-region</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#writingMode-horizontal-lr</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#writingMode-horizontal-rl</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#writingMode-horizontal</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
            <tr>
              <td><code>#zIndex</code></td>
              <td>prohibited</td>
              <td></td>
            </tr>
          </tbody>
        </table>
      </section>
    </section>
    <section id="workflow" class="informative appendix">
      <h2>Workflow</h2>
      <section id="workflow-diagram">
        <h3>Figure 1 Diagram showing Audio Description Workflow</h3>
        <p>
          The following diagram illustrates the workflow related to the proposed profile described by this document:
        </p>
        <p>
          <img src="Audio_Description_Requirements_Diagrams.png" alt="Audio Description Workflow diagram" width="458" height="860">
        </p>
        <p>
          It is proposed that after each process in this workflow the output data may be either inserted into a manifest document such as a TTML document or referenced by it.
        </p>
      </section>
      <section id="workflow-processes">
      <h3>Workflow Processes</h3>
        <table class="simple">
          <thead>
            <tr>
              <th style="width:35%">Process step</th>
              <th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>1. Identify gaps in programme dialog</td>
              <td>Automatically or manually process the programme audio track to identify intervals within which description audio may be inserted.</td>
            </tr>
            <tr>
              <td>2. Write script</td>
              <td>Write a set of descriptions to fit within the identified gaps.</td>
            </tr>
            <tr>
              <td>3. 'Voice' the script or </br>synthesise audio</td>
              <td>Generate an audio rendition of the script either by using an actor or voicer and recording the speech or synthesise the audio description by using a text to speech system. This is typically a mono audio track that may be delivered as a single track that is the same duration as the programme or as a set of short audio tracks each beginning at a defined time.</td>
            </tr>
            <tr>
              <td>4. Define AD track </br>left/right pan data</td>
              <td>Select a horizontal pan position to apply to the audio rendition of the description when mixing with the main programme audio.<br>This is typically a single value that applies to each description.</td>
            </tr>
            <tr>
              <td>5. Define main programme</br> audio levels during AD</td>
              <td>Select the amount by which to lower the main programme audio prior to mixing in the description audio.<br>This is typically defined as a curve defined by a set of moments in time and fade levels to apply, with an interpolation algorithm to vary the levels between each moment in time.</td>
            </tr>
            <tr>
              <td>6. Mix programme audio with descriptions</td>
              <td>Mix the programme audio with the rendered descriptions.<br>This may be pre-mixed (also known as “broadcaster mix”) prior to delivery to the audience, or mixed in real time (also known as “receiver mix”) at playback time; mixing at playback time is a requirement to enable user customisation of the relative levels of main programme audio and descriptions. See [BBC_RD_WHP051] for the reference model for this.</td>
            </tr>
          </tbody>
        </table>
      </section>
    </section>
    <section id="requirements" class="informative appendix">
      <h2>Requirements</h2>
      <p>
        The following table lists the requirements at each stage of the workflow:
      </p>
      <table class="simple">
        <thead>
          <tr>
            <th style="width:20%">Requirement ID</th>
            <th style="width:15%">Process step</th>
            <th>Requirement</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>ADR1</td>
            <td>1</td>
            <td>
              <ul style="list-style-type:disc">
                <li>The document must be able to define a list of intervals, each defined by a begin time and an end time that are opportunities for adding descriptions.</li>
                <li>[[MAUR]] DV-2 Render descriptions in a time-synchronized manner, using the primary media resource as the timebase master.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td>ADR2</td>
            <td>2</td>
            <td>
              <ul style="list-style-type:disc">
                <li>The document must be able to incorporate description text to be voiced, each description located within a timed interval defined by a begin time and an end time.</li>
                <li>[[MAUR]] TVD-2 TVDs need to be provided in a format that contains the following information:
                  <ol type="a">
                    <li>start time, text per description cue (the duration is determined dynamically, though an end time could provide a cut point)</li>
                    <li>possibly a speech-synthesis markup to improve quality of the description (existing speech synthesis markups include SSML and CSS 3 Speech Module)</li>
                    <li>accompanying metadata providing labeling for speakers, language, etc. and</li>
                    <li>visual style markup.</li>
                  </ol>
                </li>
              </ul>
            </td>
          </tr>
          <tr>
            <td>ADR3</td>
            <td>2</td>
            <td>
              <ul style="list-style-type:disc">
                <li>The document must be able to incorporate additional user defined metadata associated with each description; metadata schemes may be user defined or centrally defined.
                For example the language of the description may be stored, notes made by the script writer.</li>
                <li>[[MAUR]] DV-10 Allow the user to select from among different languages of descriptions, if available, even if they are different from the language of the main soundtrack.</li>
                <li>[[MAUR]] DV-13 Support metadata, such as   copyright information, usage rights, language, etc.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td>ADR4</td>
            <td>2</td>
            <td>
              <ul style="list-style-type:disc">
                <li>The document must be extensible to allow incorporation of data required to achieve the desired quality of audio presentation, whether manual or automated.
                  For example it is typical to include information about what gender and age voice would be appropriate to voice the descriptions;
                  it is also feasible to include data used to improve the quality of text to speech synthesis, such as phonetic descriptions of the text, intonation and emotion data etc.</li>
                <li>The format of any  extensions for this purpose need not be defined.</li>
            </td>
          </tr>
          <tr>
            <td>ADR12</td>
            <td>3</td>
            <td>
              <ul style="list-style-type:disc">
                <li>The document must be able to reference audio tracks either included as binary data within the document or separately.</li>
                <li>[[MAUR]] DV-4 Support recordings of high quality speech as a track of the media resource, or as an external file.</li>
                <li>[[MAUR]] DV-9 Allow the author to use a codec which is optimized for voice only, rather than requiring the same codec as the original soundtrack.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td>ADR5</td>
            <td>3</td>
            <td>
              <ul style="list-style-type:disc">
                <li>The document must be able to associate a begin time with the beginning of playback of each audio track, for the case that multiple audio tracks are created, one per description.</li>
                <li>[[MAUR]] DV-2 Render descriptions in a time-synchronized manner, using the primary media resource as the timebase master.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td>ADR6</td>
            <td>3</td>
            <td>
              <ul style="list-style-type:disc">
                <li>The document must be able to associate a begin time with a playback entry time within an audio track, for the case that a single audio track is generated that is the same duration as the main programme audio.</li>
                <li>The begin time and the playback entry time may be required to be synchronous (coincident values) within the document structure.</li>
                <li>[[MAUR]] DV-2 Render descriptions in a time-synchronized manner, using the primary media resource as the timebase master.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td>ADR7</td>
            <td>4</td>
            <td>
              <ul style="list-style-type:disc">
                <li>The document must be able to associate a left/right pan value with playback of each or every audio description.
                  This value applies to the audio description prior to mixing with the main programme audio.</li>
                <li>[[MAUR]] DV-8 Allow the author to provide fade and pan controls to be accurately synchronized with the original soundtrack.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td>ADR8</td>
            <td>5</td>
            <td>
              <ul style="list-style-type:disc">
                <li>The document must be able to define a fade level curve that applies to the main programme audio prior to mixing with the audio description, where that fade level curve is defined by a set of pairs of level and times and an interpolation algorithm. </li>
                <li>[[MAUR]] DV-5 Allow the author to independently adjust the volumes of the audio description and original soundtracks where these are available as separate audio channel resources.</li>
                <li>[[MAUR]] DV-7 Permit smooth changes in volume rather than stepped changes. The degree and speed of volume change should be under user control.</li>
                <li>[[MAUR]] DV-8 Allow the author to provide fade and pan controls to be accurately synchronized with the original soundtrack.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td>ADR9</td>
            <td>6</td>
            <td>
              <ul style="list-style-type:disc">
                <li>The processor must be able to generate a set of directives to control an audio mixer to generate the desired audio description mixed audio track honouring the pan and fade information within the document.</li>
                <li>The format of those directives may be implementation dependent.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td>ADR10</td>
            <td>6</td>
            <td>
              <ul style="list-style-type:disc">
                <li>The processor may modify the audio mixer control directives under user control to customise the relative levels of main programme audio and audio description, and the pan information.</li>
                <li>[[MAUR]] DV-6 Allow the user to independently adjust the volumes of the audio description and original soundtracks (where these are available as separate audio channel resources), with the user's settings overriding the author's.</li>
                <li>[[MAUR]] DV-12 Allow the user to relocate the pan location of the various audio tracks within the audio field, with the user setting overriding the author setting.</br>
                  The setting should be re-adjustable as the media plays.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td>ADR11</td>
            <td>6</td>
            <td>
              <ul style="list-style-type:disc">
                <li>The audio mixing transitions and semantics must be implementable using [[WEBAUDIO]], specifically relating to the application of gain and pan as defined therein and the interpolation between values.</li>
              </ul>
            </td>
          </tr>
        </tbody>
      </table>
      <p class ="note">
        [[WEBAUDIO]] specifies three interpolation mechanisms for traversing from one parameter value to another: linear, exponential and linear interpolation between points on a curve, where the default ramp e.g. for setTargetAtTime uses an exponential interpolation.
      </p>
    </section>
    
    <section class="appendix" id="webaudio-section">
      <h2>Web Audio Mixing</h2>
      <p>
        <img src="Web Audio Graph.png" alt="An image illustrating the effect of pan and gain on audio in a WEBAUDIO process" width="100%">
      </p>
      <p>
        Every content element in the audio tree creates a mixer that adds the audio from its parent and its audio element children, and optionally applies a pan and gain to the output.
      </p>
      <p>
        Every audio element provides an audio input from some audio resource, with its own pan and gain.
      </p>
      <p>
        The output of every content element’s audio is passed to each of its children.
      </p>
      <p>
        The audio output of all the leaf content elements is mixed together on the “master bus” in Web Audio terms.
      </p>
      <pre class="example"
        data-include="examples/gain-example.xml"
        data-include-format="text">
      </pre>

      <p>
        <img src="Gain image.png" alt="An image illustrating the effect of gain on audio levels" width="100%">
      </p>
    </section>

    <section class="appendix informative" id="bbc-example-section">
      <h2>Real world worked example: BBC</h2>
      <p>This section includes part of a real world audio description script
      generated by the BBC for its Eastenders television programme.</p>
      <pre class="example"
        data-include="examples/bbc-eastenders-ad.xml"
        data-include-format="text">
      </pre>
      <p>
        We have a div element that wraps all the other content. Crucially it includes two audio element children, which do a few things:
        <ul>
          <li>They make that parent element an Audio generating element, which means that the player code needs to create a Web Audio graph node for it.</li>
          <li>They tell the player to add ;track=1 (whatever that means) in and pan it all the way to the left, i.e. tts:pan="-1".</li>
          <li>They tell the player to add ;track=2 (whatever that means) in and pan it all the way to the right, i.e. tts:pan="1".</li>
        </ul>
      </p>
      <p>
        We need a convention to identify "tracks that are provided to us from somewhere else", and in this case we've defined ;track=n to do that.
      </p>
      <p>
        Then there are bunch of child p elements that each have a begin and end time.
        They each represent a snippet of audio description and the time during which some stuff happens.
        The text of the audio description is contained in a child span element, which itself has begin and end times.
        The span's begin and end times are relative to the parent p element's begin time.
      </p>
      <p>
        There is some metadata there too, which might be helpful during the authoring process, for example.
      </p>
      <p>
        A few things need to happen for each snippet of audio description:
        <ul type="1">
          <li>Fade down the programme audio level.</li>
          <li>Play the audio description audio chunk, stereo panned to the right place.</li>
          <li>Fade the programme audio back up.</li>
        </ul>
      </p>
      <p>
        The fade up and down are both achieved by placing animate elements as children of the p element.
        They smoothly change ("continuously animate") the tta:gain value between values, in a semi-colon separated list, where the begin and end times of the animation are specified on the element and are relative to the parent p element's begin time.
        The audio that they modify is the audio that is available to that element, i.e. the programme audio that comes down to the p from the parent div (remember that specified some audio? This is where it goes).
      </p>
      <p>
        Playing the audio description is done by adding a new audio child to the span.
        The playback begins in the presentation at the span's begin time, and the clipBegin and clipEnd mark the in and out points of the referenced audio resource to play, which is specified by the src attribute.
        If we wanted to specify a left/right pan value, we could do that by setting a tta:pan attribute on the audio element itself.
        Similarly we could vary the level of the audio by setting a tta:gain value.
      </p>
      <p>
        This structure is implemented in the mixing code by constructing a Web Audio Graph, where the outputs of all the spans are, in the end, mixed together.
      </p>
    </section>
    
    <section class="appendix" id="acknowledgements-section">
      <h2>Acknowledgements)</h2>
        <p>
          The editor acknowledges the current and former members of the <abbr title="World Wide Web Consortium">W3C</abbr> Timed Text Working Group (TTWG), the members of other W3C Working Groups,
          and industry experts in other forums who have contributed directly or indirectly to the process or content of this document.
        </p>
        <p>
          The editors wish to especially acknowledge the contributions by:
        </p>
    </section>
  </body>
</html>
